import OpenAI from "openai";
import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";
import readline from "readline/promises";
import dotenv from "dotenv";

// load environment variables from .env
dotenv.config();

const openai = new OpenAI({
    apiKey: process.env.API_KEY,
    baseURL: process.env.BASE_URL
});

class MCPClient {
    mcp;
    llm;
    transport = null;
    tools = [];
    constructor() {
        // Initialize llm client and MCP client
        this.callModel = openai.chat.completions.create.bind(openai.chat.completions);
        this.mcp = new Client({ name: "mcp-client-cli", version: "1.0.0" });
    }

    /**
     * åŸºäº mcp è§„èŒƒ
     * 1. å»ºç«‹å’Œ client å’Œ server ç«¯çš„è¿æ¥
     * 2. æ‹‰å– mcp-server æä¾›çš„å·¥å…·åˆ—è¡¨ï¼ˆtool listï¼‰
     * 
     */
    async connectToServer(serverScriptPath) {
        /**
         * Connect to an MCP server
         *
         */
        try {
            // Initialize transport and connect to server
            this.transport = new StdioClientTransport({
                command: process.execPath,
                args: [serverScriptPath],
            });
            this.mcp.connect(this.transport);
            // List available tools
            const toolsResult = await this.mcp.listTools();
            // è½¬æ¢æˆæ¨¡å‹è®¤è¯†çš„ tool æ ¼å¼
            this.tools = toolsResult.tools.map((tool) => {
                return {
                    type: "function",
                    function: {
                        name: tool.name,
                        description: tool.description,
                        parameters: tool.inputSchema,
                    },
                };
            });
            console.log("Connected to server with tools:", this.tools.map(({ function: { name } }) => name));
        }
        catch (e) {
            console.log("Failed to connect to MCP server: ", e);
            throw e;
        }
    }

    /**
     * è°ƒç”¨å¤§æ¨¡å‹
     * æ¨¡å‹ä¼šè‡ªå·±æ„ŸçŸ¥éœ€è¦è°ƒå“ªäº›å·¥å…·
     * 
     * åœ¨éœ€è¦å·¥å…·è°ƒç”¨çš„åœºæ™¯ä¸‹
     * åˆ©ç”¨ mcp æä¾›çš„èƒ½åŠ›å®ç°å·¥å…·è°ƒç”¨å¹¶æ‹¿åˆ°ç»“æœï¼Œç„¶åå†æ¬¡è°ƒç”¨å¤§æ¨¡å‹å°±å¯ä»¥æ‹¿åˆ°æœ€åå›ç­”
     */
    async processQuery(query) {
        /**
         * Process a query using llm and available tools
         *
         * @param query - The user's input query
         * @returns Processed response as a string
         */
        const messages = [
            {
                role: "user",
                content: query,
            },
        ];
        const response = await this.callModel({
            model: "qwen-turbo",
            messages,
            tools: this.tools,
            parallel_tool_calls: true,
        });

        const finalText = [];
        const delta = response.choices[0]?.message;
        const { tool_calls, content } = delta || {};
        // console.dir(delta, { depth: null })

        if (tool_calls?.length && content) {
            finalText.push('llm è°ƒç”¨å·¥å…·çš„æ€è€ƒè¿‡ç¨‹ğŸ¤”: ', content);
        } else if (content) {
            finalText.push(content);
        }
        if (tool_calls?.length) {
            // Execute tool calls in parallel
            const toolCalls = await Promise.all(tool_calls.map(async (toolCall) => {
                const functionName = toolCall?.function?.name;
                const functionArgs = JSON.parse(toolCall?.function?.arguments || `{}`);
                const toolName = functionName;
                const toolArgs = functionArgs;

                console.log(`\n[Calling tool ${toolName} with args ${JSON.stringify(toolArgs)}, waiting...]`);
                const toolResponse = await this.mcp.callTool({
                    name: toolName,
                    arguments: toolArgs,
                });

                return {
                    toolCall,
                    functionName,
                    functionArgs,
                    toolResponse
                };
            }));

            // å°†æ‰€æœ‰ AI å†³ç­–çš„å·¥å…·è°ƒç”¨ä¿¡æ¯æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            messages.push({
                role: "assistant",
                content: null,
                tool_calls: toolCalls.map(({ toolCall, functionName, functionArgs }) => ({
                    id: toolCall.id,
                    type: "function",
                    function: {
                        name: functionName,
                        arguments: JSON.stringify(functionArgs),
                    }
                }))
            });

            // å°†æ‰€æœ‰å·¥å…·è°ƒç”¨çš„ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            toolCalls.forEach(({ functionName, toolResponse }) => {
                messages.push({
                    role: "tool",
                    name: functionName,
                    content: JSON.stringify(toolResponse)
                });
            });
            // console.dir(messages, { depth: null })
            // Get next response from llm, å‡è®¾è¿™é‡Œåªä¼šè°ƒç”¨ä¸€æ¬¡å·¥å…·ï¼ˆå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦å¾ªç¯è°ƒç”¨å·¥å…·ç›´åˆ°æ²¡æœ‰å·¥å…·è°ƒç”¨ä¸ºæ­¢ï¼‰
            const response = await this.callModel({
                model: "qwen-turbo",
                messages,
            });
            // console.dir(response, { depth: null })
            finalText.push(response.choices[0]?.message?.content || "");
        }
        return finalText.join("\n");
    }

    /**
     * 
     * åˆ›å»ºäº†ä¸€ä¸ªå¯¹è¯æµ
     * åœ¨å‘½ä»¤è¡Œé‡Œæ¥æ”¶è¾“å…¥ï¼Œç„¶åè¾“å‡ºå¤§æ¨¡å‹çš„å›ç­”
     */
    async chatLoop() {
        /**
         * Run an interactive chat loop
         */
        const rl = readline.createInterface({
            input: process.stdin,
            output: process.stdout,
        });

        try {
            console.log("\nMCP Client Started!");
            console.log("Type your queries or 'quit' to exit.");
            while (true) {
                const message = await rl.question("\nQuery: ");
                if (message.toLowerCase() === "quit") {
                    break;
                }
                try {
                    const response = await this.processQuery(message);
                    console.log("\n" + response);
                }
                catch (e) {
                    console.log("Error processing query: ", e);
                }
            }
        } finally {
            rl.close();
        }
    }

    async cleanup() {
        /**
         * Clean up resources
         */
        await this.mcp.close();
    }
}

async function main() {
    if (process.argv.length < 3) {
        console.log("Usage: node build/index.js <path_to_server_script>");
        return;
    }

    const mcpClient = new MCPClient();
    try {
        await mcpClient.connectToServer(process.argv[2]);
        await mcpClient.chatLoop();
    } catch (e) {
        console.log("Error: ", e);
    } finally {
        await mcpClient.cleanup();
        process.exit(0);
    }
}

main();
